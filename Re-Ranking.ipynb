{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SelmaDM/Pyterrier/blob/master/Re-Ranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9egyhuvU3_GI"
      },
      "source": [
        "# PyTerrier - Neural Re-Ranking \n",
        "\n",
        "Dans ce TP vous allez :\n",
        "\n",
        " - reclasser des documents en utilisant des modèles neuronaux comme KNRM, Vanilla BERT, EPIC et monoT5.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl0-Gs6e5I7n"
      },
      "source": [
        "# Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zSgDzjKxqfq5"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade python-terrier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV0C6jJvqhMR"
      },
      "source": [
        "### Installation des plugins Pyterrier  \n",
        "\n",
        "Nous installons les plugins PyTerrier [OpenNIR](https://opennir.net/) et [monoT5](https://github.com/terrierteam/pyterrier_t5). Vous pouvez ignorer sans risque les erreurs de version des paquets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AkIR_PXdet7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b085d78e-b543-4508-9298-3e72f5cdc678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade git+https://github.com/Georgetown-IR-Lab/OpenNIR\n",
        "!pip install -q --upgrade git+https://github.com/terrierteam/pyterrier_t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-nQrpNP5pN7"
      },
      "source": [
        "## Preliminary steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H7TDkDIQuDR"
      },
      "source": [
        "Ces lignes sont nécessaires pour travailler avec DeepCT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lPozTq7K4bVo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSUwC6S7QkQY"
      },
      "source": [
        "**[PyTerrier](https://github.com/terrier-org/pyterrier) initialization** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6FegcyWr5lja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4716cb-6ef7-4158-d06e-5561187e2159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "terrier-assemblies 5.7 jar-with-dependencies not found, downloading to /root/.pyterrier...\n",
            "Done\n",
            "terrier-python-helper 0.0.7 jar not found, downloading to /root/.pyterrier...\n",
            "Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ]
        }
      ],
      "source": [
        "import pyterrier as pt\n",
        "if not pt.started():\n",
        "    pt.init()\n",
        "\n",
        "cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
        "\n",
        "\n",
        "from pyterrier.measures import * # allow for natural measure names\n",
        "import onir_pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF3HIPhtrqOH"
      },
      "source": [
        "### Indexation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6oCcP90yrlGi"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./terrier_cord19/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y35hw8l7XVEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "c65312a5083044218c2038712f2655d4",
            "7b5b47578bb84c40b7fb1a52016fe34e",
            "143c3a749f4b4f828ff2fc6abddd08f9",
            "687a51bc6f444b20b34ac4a6b549ccbf",
            "be37b35cb5634f1398e2f6cc9fcb2679",
            "f065dbc303df476093a8fcfe61e38ca2",
            "4c3ef5d6a5d44c699e134fb53127fab3",
            "a5ba24f88d9d421696122f0d9896e483",
            "5f11968f54134136b75adea95c6f8eca",
            "7d5571ddcdf647dcaa3f1bb27b8e3ba4",
            "c6b29c6b5a1248f8866865bb1280b247"
          ]
        },
        "outputId": "f91f1dbb-ca13-4405-a015-b4524bd800a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] [starting] building docstore\n",
            "[INFO] If you have a local copy of https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv, you can symlink it here to avoid downloading it again: /root/.ir_datasets/downloads/80d664e496b8b7e50a39c6f6bb92e0ef\n",
            "[INFO] [starting] https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv\n",
            "docs_iter:   0%|                                    | 0/192509 [512ms<?, ?doc/s]\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 0.0%| 0.00/269M [0ms<?, ?B/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 0.0%| 65.5k/269M [154ms<10:34, 425kB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 0.1%| 270k/269M [308ms<05:07, 877kB/s] \u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 0.4%| 1.06M/269M [473ms<01:60, 2.24MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 1.5%| 4.15M/269M [572ms<36.53s, 7.26MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 2.7%| 7.25M/269M [724ms<26.15s, 10.0MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 4.1%| 11.1M/269M [883ms<20.54s, 12.6MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 5.7%| 15.5M/269M [983ms<16.12s, 15.7MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 7.4%| 19.8M/269M [1.14s<14.38s, 17.3MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 9.0%| 24.2M/269M [1.30s<13.17s, 18.6MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 10.6%| 28.6M/269M [1.47s<12.33s, 19.5MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 12.2%| 33.0M/269M [1.63s<11.66s, 20.3MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 13.9%| 37.3M/269M [1.74s<10.78s, 21.5MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 15.5%| 41.7M/269M [1.89s<10.31s, 22.1MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 17.1%| 46.1M/269M [2.05s<9.90s, 22.5MB/s] \u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 18.7%| 50.5M/269M [2.21s<9.58s, 22.8MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 20.4%| 54.8M/269M [2.37s<9.25s, 23.2MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 22.0%| 59.2M/269M [2.47s<8.76s, 24.0MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 23.6%| 63.6M/269M [2.62s<8.49s, 24.2MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 25.2%| 68.0M/269M [2.78s<8.23s, 24.5MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 26.9%| 72.3M/269M [2.88s<7.84s, 25.1MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 28.5%| 76.7M/269M [3.03s<7.59s, 25.3MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 30.1%| 81.1M/269M [3.13s<7.26s, 25.9MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 31.7%| 85.5M/269M [3.28s<7.05s, 26.0MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 33.4%| 89.8M/269M [3.43s<6.86s, 26.2MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 35.0%| 94.2M/269M [3.54s<6.57s, 26.6MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 36.6%| 98.6M/269M [3.69s<6.39s, 26.7MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 38.2%| 103M/269M [3.85s<6.21s, 26.8MB/s] \u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 39.9%| 107M/269M [3.95s<5.96s, 27.2MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 41.5%| 112M/269M [4.11s<5.79s, 27.2MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 43.1%| 116M/269M [4.26s<5.61s, 27.3MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 44.7%| 120M/269M [4.37s<5.40s, 27.5MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 46.4%| 125M/269M [4.51s<5.21s, 27.7MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 48.0%| 129M/269M [4.63s<5.02s, 27.9MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 49.6%| 134M/269M [4.76s<4.84s, 28.0MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 51.2%| 138M/269M [4.89s<4.65s, 28.2MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 52.9%| 142M/269M [5.02s<4.47s, 28.4MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 54.5%| 147M/269M [5.14s<4.29s, 28.5MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 56.1%| 151M/269M [5.28s<4.13s, 28.6MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 57.7%| 155M/269M [5.43s<3.97s, 28.6MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 59.4%| 160M/269M [5.58s<3.82s, 28.7MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 61.0%| 164M/269M [5.75s<3.67s, 28.6MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 62.6%| 169M/269M [5.87s<3.50s, 28.7MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 64.2%| 173M/269M [6.01s<3.35s, 28.8MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 65.9%| 177M/269M [6.15s<3.19s, 28.8MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 67.5%| 182M/269M [6.28s<3.03s, 28.9MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 69.1%| 186M/269M [6.43s<2.87s, 29.0MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 70.7%| 190M/269M [6.58s<2.72s, 29.0MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 72.4%| 195M/269M [6.72s<2.57s, 29.0MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 74.0%| 199M/269M [6.87s<2.41s, 29.0MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 75.6%| 204M/269M [7.01s<2.26s, 29.0MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 77.2%| 208M/269M [7.14s<2.10s, 29.1MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 78.9%| 212M/269M [7.28s<1.95s, 29.2MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 80.5%| 217M/269M [7.41s<1.80s, 29.2MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 82.1%| 221M/269M [7.54s<1.64s, 29.3MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 83.7%| 225M/269M [7.67s<1.49s, 29.4MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 85.4%| 230M/269M [7.81s<1.34s, 29.4MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 87.0%| 234M/269M [7.98s<1.19s, 29.4MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 88.6%| 239M/269M [8.11s<1.04s, 29.4MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 90.2%| 243M/269M [8.26s<893ms, 29.4MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 91.9%| 247M/269M [8.38s<742ms, 29.5MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 93.5%| 252M/269M [8.55s<595ms, 29.4MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 95.1%| 256M/269M [8.68s<446ms, 29.5MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 96.7%| 260M/269M [8.81s<297ms, 29.6MB/s]\u001b[A\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: 98.4%| 265M/269M [8.94s<148ms, 29.6MB/s]\u001b[A\n",
            "\n",
            "\u001b[A[INFO] [finished] https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: [9.07s] [269MB] [29.7MB/s]\n",
            "docs_iter:   0%|                                    | 0/192509 [9.60s<?, ?doc/s]\n",
            "https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: [9.09s] [269MB] [29.6MB/s]\u001b[A\n",
            "docs_iter: 100%|██████████████████████| 192509/192509 [36.42s<0ms, 5285.14doc/s]\n",
            "[INFO] [finished] docs_iter: [36.43s] [192509doc] [5284.94doc/s]\n",
            "[INFO] [finished] building docstore [36.44s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "cord19/trec-covid documents:   0%|          | 0/192509 [10ms<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c65312a5083044218c2038712f2655d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-59cedea60614>:11: DeprecationWarning: specifying meta and meta_lengths in IterDictIndexer.index() is deprecated, use constructor instead\n",
            "  index_ref = indexer.index(cord19.get_corpus_iter(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14:04:48.960 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (6iu1dtyl) - further warnings are suppressed\n",
            "14:07:03.640 [ForkJoinPool-1-worker-3] ERROR org.terrier.structures.indexing.Indexer - Could not finish MetaIndexBuilder: \n",
            "java.io.IOException: Key 8lqzfj2e is not unique: 37597,11755\n",
            "For MetaIndex, to suppress, set metaindex.compressed.reverse.allow.duplicates=true\n",
            "\tat org.terrier.structures.collections.FSOrderedMapFile$MultiFSOMapWriter.mergeTwo(FSOrderedMapFile.java:1374)\n",
            "\tat org.terrier.structures.collections.FSOrderedMapFile$MultiFSOMapWriter.close(FSOrderedMapFile.java:1308)\n",
            "\tat org.terrier.structures.indexing.BaseMetaIndexBuilder.close(BaseMetaIndexBuilder.java:321)\n",
            "\tat org.terrier.structures.indexing.classical.BasicIndexer.indexDocuments(BasicIndexer.java:270)\n",
            "\tat org.terrier.structures.indexing.classical.BasicIndexer.createDirectIndex(BasicIndexer.java:388)\n",
            "\tat org.terrier.structures.indexing.Indexer.index(Indexer.java:377)\n",
            "\tat org.terrier.python.ParallelIndexer$3.apply(ParallelIndexer.java:131)\n",
            "\tat org.terrier.python.ParallelIndexer$3.apply(ParallelIndexer.java:120)\n",
            "\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)\n",
            "\tat java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)\n",
            "\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)\n",
            "\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)\n",
            "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:952)\n",
            "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:926)\n",
            "\tat java.base/java.util.stream.AbstractTask.compute(AbstractTask.java:327)\n",
            "\tat java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746)\n",
            "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n",
            "\tat java.base/java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:408)\n",
            "\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:736)\n",
            "\tat java.base/java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:919)\n",
            "\tat java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)\n",
            "\tat java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558)\n",
            "\tat org.terrier.python.ParallelIndexer$4.call(ParallelIndexer.java:140)\n",
            "\tat org.terrier.python.ParallelIndexer$4.call(ParallelIndexer.java:137)\n",
            "\tat java.base/java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1448)\n",
            "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n",
            "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n",
            "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n",
            "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n",
            "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n",
            "14:07:29.940 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 54937 empty documents\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "pt_index_path = './terrier_cord19'\n",
        "\n",
        "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
        "    # create the index, using the IterDictIndexer indexer \n",
        "    indexer = pt.index.IterDictIndexer(pt_index_path, blocks=True)\n",
        "\n",
        "    # we give the dataset get_corpus_iter() directly to the indexer\n",
        "    # while specifying the fields to index and the metadata to record\n",
        "    index_ref = indexer.index(cord19.get_corpus_iter(), \n",
        "                              fields=('abstract',), \n",
        "                              meta=('docno',))\n",
        "\n",
        "else:\n",
        "    # if you already have the index, use it.\n",
        "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwDams5M7g6c"
      },
      "source": [
        "## Re-Rankers \n",
        "\n",
        "Commençons à explorer quelques méthodes neuronales de re-classement ! Nous pouvons les construire à partir de zéro en utilisant `onir_pt.reranker`.\n",
        "\n",
        "Le modèle de re-ranking d'OpenNIR est composé de :\n",
        " - `ranker` (par exemple, `drmm`, `knrm`, ou `pacrr`). Ceci définit l'architecture neuronale de classement.\n",
        " - `vocab` (par exemple, `wordvec_hash`, ou `bert`). Ceci définit comment le texte est encodé par le modèle. Cette approche rend facile l'échange de différentes représentations de texte.\n",
        "\n",
        "L'exécution de cette ligne prendra quelques minutes car elle télécharge et prépare les vecteurs de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0O79K2K6fvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b727cc0-98ae-4100-a781-0e2dada498f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config file not found: config\n",
            "\u001b[02;37m[2023-03-17 14:07:30,030][WordvecHashVocab][DEBUG] \u001b[0m\u001b[37m[starting] downloading https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[02;37m[2023-03-17 14:07:46,294][onir.util.download][WARNING] \u001b[0m\u001b[33mno hash provided for https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip; consider adding expected_md5=\"3cc8839ac3fa9a6187149b1e73328b2a\" to ensure data integrity.\u001b[0m\n",
            "\u001b[02;37m[2023-03-17 14:07:46,306][onir.util.download][DEBUG] \u001b[0m\u001b[37mdownloaded https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip [15.68s] [682M] [36.2MB/s]\u001b[0m\n",
            "\u001b[02;37m[2023-03-17 14:07:46,315][WordvecHashVocab][DEBUG] \u001b[0m\u001b[37m[finished] downloading https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip [16.29s]\u001b[0m\n",
            "\u001b[02;37m[2023-03-17 14:07:46,315][WordvecHashVocab][DEBUG] \u001b[0m\u001b[37m[starting] extracting vecs\u001b[0m\n",
            "\u001b[02;37m[2023-03-17 14:08:09,887][WordvecHashVocab][DEBUG] \u001b[0m\u001b[37m[finished] extracting vecs [23.57s]\u001b[0m\n",
            "\u001b[02;37m[2023-03-17 14:08:09,888][WordvecHashVocab][DEBUG] \u001b[0m\u001b[37m[starting] loading vecs into memory\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "knrm = onir_pt.reranker('knrm', 'wordvec_hash', text_field='abstract')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1avVTpxDORN"
      },
      "source": [
        "Voyons comment ces modèles fonctionnent pour le classement !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3WhKIVAcC6E"
      },
      "outputs": [],
      "source": [
        "tfidf = pt.BatchRetrieve(index_ref, wmodel=\"TF_IDF\") % 50\n",
        "get_text = pt.text.get_text(cord19, 'abstract') #>> pt.apply.title_abstract(lambda r: r['title'] + ' ' + r['abstract'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJYpJedQMRp5"
      },
      "outputs": [],
      "source": [
        "topics = cord19.get_topics(variant='description')\n",
        "qrels = cord19.get_qrels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im_0UTIoMz1j"
      },
      "outputs": [],
      "source": [
        "SEED=42\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tr_va_topics, test_topics = train_test_split(topics, test_size=15, random_state=SEED)\n",
        "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=5, random_state=SEED)\n",
        "\n",
        "\n",
        "test_qrels = qrels # seulement les annotations des topics en réponse sont utilisés, donc pas de problème si on utilise tout\n",
        "train_qrels = qrels\n",
        "valid_qrels = qrels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FWUIN577v1O"
      },
      "outputs": [],
      "source": [
        "\n",
        "# build a sub-pipeline to get the concatenated title and abstract text\n",
        "pipeline = tfidf >> get_text >> knrm\n",
        "pt.Experiment(\n",
        "    [tfidf, pipeline],\n",
        "    test_topics,\n",
        "    qrels,\n",
        "    names=['TFIDF', 'TFIDF >> KNRM'],\n",
        "    eval_metrics=[AP(rel=2), nDCG, nDCG@10, P(rel=2)@10]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhquobQypVNJ"
      },
      "source": [
        "Cela ne fonctionne pas très bien car le modèle n'est pas entraîné ; il utilise des poids aléatoires pour combiner les scores de la matrice de similarité."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLv7quA43yAP"
      },
      "source": [
        "## Entraînement du re-ranker\n",
        "\n",
        "Vous pouvez entraîner des modèles de re-classement dans PyTerrier en utilisant la méthode `fit`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evgsliedVXat"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(\n",
        "    train_topics,\n",
        "    train_qrels,\n",
        "    valid_topics,\n",
        "    valid_qrels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQPsVUpDOzr1"
      },
      "outputs": [],
      "source": [
        "pt.Experiment(\n",
        "    [tfidf, pipeline],\n",
        "    test_topics,\n",
        "    qrels,\n",
        "    names=['TFIDF', 'TFIDF >> KNRM (trained)'],\n",
        "    eval_metrics=[AP(rel=2), nDCG, nDCG@10, P(rel=2)@10]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le résultat est plus élévé, mais cela reste moins bon que le TFIDF. Proposez une hypothèse sur le problème."
      ],
      "metadata": {
        "id": "Wo_t32oxMste"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79l1jn0pRQEY"
      },
      "source": [
        "## Vanilla BERT\n",
        "\n",
        "Les modèles linguistiques contextualisés, tels que [BERT] (https://arxiv.org/abs/1810.04805), sont des modèles neuronaux beaucoup plus puissants qui se sont avérés efficaces pour le classement.\n",
        "\n",
        "Nous allons essayer d'utiliser une version \"vanille\" (ou \"mono\") du modèle BERT. Le modèle BERT est pré-entraîné pour la modélisation du langage et la prédiction de la phrase suivante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qlXPHqN3iO0"
      },
      "outputs": [],
      "source": [
        "#del knrm # clear out memory from KNRM\n",
        "vbert = onir_pt.reranker('vanilla_transformer', 'bert', text_field='abstract', vocab_config={'train': True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "progrVwaunrn"
      },
      "source": [
        "Voyons comment ce modèle se comporte sur TREC COVID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkasovrjQjy0"
      },
      "outputs": [],
      "source": [
        "pipeline = tfidf % 50 >> get_text >> vbert\n",
        "pt.Experiment(\n",
        "    [tfidf, pipeline],\n",
        "    test_topics,\n",
        "    qrels,\n",
        "    names=['TFIDF', 'TFIDF >> VBERT'],\n",
        "    baseline=0,\n",
        "    eval_metrics=[AP(rel=2), nDCG, nDCG@10, P(rel=2)@10]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBrfNZ_1u_pD"
      },
      "source": [
        "Comme nous le constatons, bien que le modèle soit pré-entraîné, il n'obtient pas de très bons résultats. Cela est dû au fait qu'il n'est pas réglé pour la tâche de classement par pertinence.\n",
        "\n",
        "Cependant, nous pouvons entraîner le modèle pour le classement (comme indiqué ci-dessus pour KNRM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdUPsiYLX-L1"
      },
      "source": [
        "## monoT5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1UoVYscxzR_"
      },
      "source": [
        "Le modèle [monoT5](https://arxiv.org/abs/2003.06713) évalue les documents à l'aide d'un modèle de langage causal. Voyons comment cette approche fonctionne sur TREC COVID.\n",
        "\n",
        "La classe `MonoT5ReRanker` de `pyterrier_t5` charge automatiquement une version du classeur monoT5 qui est entraînée sur le jeu de données MS MARCO passage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuWuB44kQN2f"
      },
      "outputs": [],
      "source": [
        "from pyterrier_t5 import MonoT5ReRanker\n",
        "monoT5 = MonoT5ReRanker(text_field='abstract')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FI_KCicWDeB"
      },
      "outputs": [],
      "source": [
        "pipeline = (tfidf >> get_text >> monoT5)\n",
        "pt.Experiment(\n",
        "    [tfidf, pipeline],\n",
        "    test_topics,\n",
        "    qrels,\n",
        "    names=['TFIDF', 'TFIDF >> T5'],\n",
        "    eval_metrics=[AP(rel=2), nDCG, nDCG@10, P(rel=2)@10, \"mrt\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme on pouvait s'y attendre, les résultats sont bien meilleurs en termes de NDCG@10 (0.5958 vs 0.6855)."
      ],
      "metadata": {
        "id": "-jtSau1RUdPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tâche pratique\n",
        "\n",
        "Comme pour le TP precedent, utilisez les modèles implémentés pour cord19 dans une tâche de question-réponse. Dans ce contexte, les requêtes sont de questions et les documents sont des documents qui pourraient contenir la réponse. Notez que vous devez refaire l'indexation ainsi que les autres étapes étudiées dans ce TP. Vous pouvez le télécharger le dataset en utilisant les lines de code ci-dessous."
      ],
      "metadata": {
        "id": "Up4gF2kKPHB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fiqa = {}\n",
        "fiqa['train'] = pt.datasets.get_dataset('irds:beir/fiqa/train')\n",
        "fiqa['valid'] = pt.datasets.get_dataset('irds:beir/fiqa/dev')\n",
        "fiqa['test'] = pt.datasets.get_dataset('irds:beir/fiqa/test')\n",
        "\n",
        "test_topics = fiqa['test'].get_topics(variant='text')\n",
        "test_qrels = fiqa['test'].get_qrels()\n",
        "\n",
        "train_topics = fiqa['train'].get_topics(variant='text')\n",
        "train_qrels = fiqa['train'].get_qrels()\n",
        "\n",
        "valid_topics = fiqa['valid'].get_topics(variant='text')\n",
        "valid_qrels = fiqa['valid'].get_qrels()"
      ],
      "metadata": {
        "id": "uwKll8JPPNWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation des fichiers d'indexation\n",
        "!rm -rf ./pd_index_fiqa_train\n",
        "!rm -rf ./pd_index_fiqa_test\n",
        "!rm -rf ./pd_index_fiqa_valid"
      ],
      "metadata": {
        "id": "hpDOsZKQ46PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexingFun(data_list):\n",
        "  pt_index_path_dict = {}\n",
        "  for data in data_list:\n",
        "    pt_index_path = './pd_index_fiqa' + '_' + data\n",
        "    pt_index_path_dict[data] = pt_index_path\n",
        "\n",
        "    if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
        "        # create the index, using the IterDictIndexer indexer \n",
        "        indexer = pt.index.IterDictIndexer(pt_index_path, blocks=True)\n",
        "\n",
        "        # we give the dataset get_corpus_iter() directly to the indexer\n",
        "        # while specifying the fields to index and the metadata to record\n",
        "        index_ref = indexer.index(fiqa[data].get_corpus_iter())\n",
        "\n",
        "    else:\n",
        "        # if you already have the index, use it.\n",
        "        index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
        "  return pt_index_path_dict"
      ],
      "metadata": {
        "id": "BjWGtYba4_Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tpPipeline(index_ref):\n",
        "  tf = pt.BatchRetrieve(index_ref, wmodel=\"Tf\")\n",
        "  tfidf = pt.BatchRetrieve(index_ref, wmodel=\"TF_IDF\")\n",
        "  bm_25 = pt.BatchRetrieve(index_ref, wmodel='BM25')\n",
        "  \n",
        "  pipeline = ((tf %10) | (tfidf % 10)) >> bm_25\n",
        "\n",
        "  return pipeline"
      ],
      "metadata": {
        "id": "fIVlsoQa4-5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tpCharactPipeline(pipeline, data, index_ref):\n",
        "  return (pipeline) >> pt.text.get_text(data, metadata=['doc_id', 'text'], by_query=True) >> (\n",
        "      pt.transformer.IdentityTransformer()\n",
        "      ** \n",
        "      pt.BatchRetrieve(index_ref, wmodel=\"CoordinateMatch\")\n",
        "      )"
      ],
      "metadata": {
        "id": "w2ptDz9h4-uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = ['train', 'test', 'valid']\n",
        "\n",
        "names = ['Pipeline', 'FastR', 'RFR', 'Lambda']\n",
        "feature_names = ['CoordinateMatch']\n",
        "\n",
        "# Indexation\n",
        "pt_index_path_dict = indexingFun(data_list)\n",
        "\n",
        "# Pipeline Creation\n",
        "pipeline = tpPipeline(pt.IndexRef.of(pt_index_path_dict['train'] + \"/data.properties\"))\n",
        "charact_pipeline = tpCharactPipeline(pipeline, fiqa['train'], pt_index_path_dict['train'])"
      ],
      "metadata": {
        "id": "uNChP39T4-h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monoT5 = MonoT5ReRanker(text_field='text')"
      ],
      "metadata": {
        "id": "01zcKXyr4-VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_T5 = (charact_pipeline >> monoT5)\n",
        "\n",
        "pt.Experiment(\n",
        "    [pipeline, pipeline_T5],\n",
        "    test_topics,\n",
        "    test_qrels,\n",
        "    names=['Pipeline', 'Pipeline >> T5'],\n",
        "    eval_metrics=[AP(rel=2), nDCG, nDCG@10, P(rel=2)@10, \"mrt\"]\n",
        ")"
      ],
      "metadata": {
        "id": "8gcvcL6D4-GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vbert = onir_pt.reranker('vanilla_transformer', 'bert', text_field='text', vocab_config={'train': True})"
      ],
      "metadata": {
        "id": "9OL6Y1XW497K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_VBERT = (charact_pipeline >> vbert)\n",
        "pt.Experiment(\n",
        "    [pipeline, pipeline_VBERT],\n",
        "    test_topics,\n",
        "    test_qrels,\n",
        "    names=['Pipeline', 'Pipeline >> VBERT'],\n",
        "    baseline=0,\n",
        "    eval_metrics=[AP(rel=2), nDCG, nDCG@10, P(rel=2)@10]\n",
        ")"
      ],
      "metadata": {
        "id": "cWNELCJG49wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knrm = onir_pt.reranker('knrm', 'wordvec_hash', text_field='text')"
      ],
      "metadata": {
        "id": "ltT4Zu3e49g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_knrm = (charact_pipeline >> knrm)\n",
        "pt.Experiment(\n",
        "    [pipeline, pipeline_knrm],\n",
        "    test_topics,\n",
        "    test_qrels,\n",
        "    names=['Pipeline', 'Pipeline >> KNRM'],\n",
        "    eval_metrics=[AP(rel=2), nDCG, nDCG@10, P(rel=2)@10]\n",
        ")"
      ],
      "metadata": {
        "id": "_y4Pz8OC5fGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifiez-vous des avantages par rapport à l'utilisation de Learning to Rank ?"
      ],
      "metadata": {
        "id": "Z9wWmqAwPY5w"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dl0-Gs6e5I7n",
        "rwDams5M7g6c"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c65312a5083044218c2038712f2655d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b5b47578bb84c40b7fb1a52016fe34e",
              "IPY_MODEL_143c3a749f4b4f828ff2fc6abddd08f9",
              "IPY_MODEL_687a51bc6f444b20b34ac4a6b549ccbf"
            ],
            "layout": "IPY_MODEL_be37b35cb5634f1398e2f6cc9fcb2679"
          }
        },
        "7b5b47578bb84c40b7fb1a52016fe34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f065dbc303df476093a8fcfe61e38ca2",
            "placeholder": "​",
            "style": "IPY_MODEL_4c3ef5d6a5d44c699e134fb53127fab3",
            "value": "cord19/trec-covid documents: 100%"
          }
        },
        "143c3a749f4b4f828ff2fc6abddd08f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ba24f88d9d421696122f0d9896e483",
            "max": 192509,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f11968f54134136b75adea95c6f8eca",
            "value": 192509
          }
        },
        "687a51bc6f444b20b34ac4a6b549ccbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d5571ddcdf647dcaa3f1bb27b8e3ba4",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b29c6b5a1248f8866865bb1280b247",
            "value": " 192509/192509 [02:16&lt;0ms, 791.62it/s]"
          }
        },
        "be37b35cb5634f1398e2f6cc9fcb2679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f065dbc303df476093a8fcfe61e38ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c3ef5d6a5d44c699e134fb53127fab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5ba24f88d9d421696122f0d9896e483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f11968f54134136b75adea95c6f8eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d5571ddcdf647dcaa3f1bb27b8e3ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b29c6b5a1248f8866865bb1280b247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}